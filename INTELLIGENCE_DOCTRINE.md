# INTELLIGENCE_DOCTRINE.md - Fractal Batching & Dynamic Routing

## I. Foundational Principle

**Intelligence is a resource, not a lifestyle.** It has four cost dimensions:
1.  **Speed** (latency)
2.  **Power** (capability)
3.  **Privacy** (exposure)
4.  **Economy** (cost)

**No model maximizes all four.** The system must dynamically assign reasoning tasks based on context, intent, and sovereign preference.

## II. The Intelligence Router

Between the queue and the model sits the **Router**. It evaluates policy, not thoughts.

**Escalation Logic:**
1.  **Sensitivity:** Personal/Regulatory? -> Local Tier.
2.  **Urgency:** Interactive? -> Fast Tier. Background? -> Batched/Local.
3.  **Complexity:** Simple? -> Lightweight Tier. Complex? -> High-Capability Tier.
4.  **Cost Policy:** Honors the Sovereign's budget/hardware constraints.

## III. Practical Tiers (Example)

-   **Tier 0 (Deterministic):** Regex, scripts, rules. **(Preferred)**
-   **Tier 1 (Lightweight):** Classification, short summaries.
-   **Tier 2 (Mid-Tier):** Moderate synthesis.
-   **Tier 3 (High-Capability):** Complex reasoning, long context.
-   **Tier 4 (Premium Fast):** Real-time interaction.

## IV. Trade-Off Map

-   **Speed ↑** = External API, High Cost, Lower Privacy.
-   **Power ↑** = Larger Models, High Latency, More Compute.
-   **Privacy ↑** = Local Model, Lower Exposure.
-   **Economy ↑** = Batching, Lightweight Models.

## V. Fractal Batching + Routing

-   **Batching:** Reduces *frequency* of invocation.
-   **Routing:** Reduces *intensity* of invocation.
-   **Result:** Maximum **Adequacy**. Not maximum intelligence.

## VI. Chief of Staff Ontology (Zaphod)

You do not care which model speaks. You care:
-   Was the task handled?
-   Was it within policy?
-   Was it appropriate for sensitivity?

**Shift in Perspective:**
Most systems ask: *"Which model is best?"*
We ask: *"What level of intelligence is necessary?"*

**Complexity Warning:** Routing rules must remain simple. Explicit rule tree. No recursive AI deciding which AI to call.
